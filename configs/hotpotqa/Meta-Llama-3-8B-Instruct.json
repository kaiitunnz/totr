{
  "llm": {
    "engine": "openai",
    "host": "localhost",
    "port": 8010,
    "api_key": "EMPTY",
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "overriding_context_window": null
  },
  "generation": {
    "temperature": 0,
    "max_tokens": 200
  },
  "retriever": {
    "elasticsearch_host": "localhost",
    "elasticsearch_port": 9200,
    "retriever_name": "elasticsearch",
    "hit_count_per_step": 6,
    "corpus_name": "hotpotqa",
    "document_type": "title_paragraph_text",
    "skip_long_paras": true,
    "max_para_count": 15,
    "max_gen_sent_count": 10,
    "max_para_word_count": 350,
    "answer_regex": ".* answer is:? (.*)\\.?"
  },
  "qa": {
    "answer_mode": "direct",
    "cot_question_prefix": "Answer the following question by reasoning step-by-step. Precede your final answer at the end of your reasoning with \"So the answer is:\".\n",
    "direct_question_prefix": "Answer the following question. Provide only your final answer without elaboration.\n",
    "cot_answer_regex": ".* answer is:? (.*)\\.?",
    "direct_answer_regex": "^(.*?)\n",
    "remove_full_stop": true,
    "use_retriever_answer": false
  },
  "prompt": {
    "prompt_directory": "prompts",
    "prompt_dataset": "hotpotqa",
    "cot_prompt_filename": "gold_with_3_distractors_context_cot_qa_flan_t5.txt",
    "direct_prompt_filename": "gold_with_3_distractors_context_direct_qa_flan_t5.txt",
    "prompt_set": "1"
  },
  "totr": {
    "retriever_gen_config_dict": {
      "max_tokens": 200,
      "temperature": 0.2
    }
  },
  "scr": {
    "retriever_gen_config_dict": {
      "max_tokens": 200,
      "temperature": 0.5
    }
  }
}
